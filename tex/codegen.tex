\vspace{-0.25cm}
\section{Compiling the \framework{} IR Layers}

Since the main contribution of this paper is not in introducing new techniques for code generation, we only provide a high level overview of how \framework{} generates the IR layers and target code.  Throughout the section, we refer the reader to the necessary literature related to code generation for more details.

In order to generate code, a \framework{} user provides an algorithm and a set of scheduling commands.  Code generation is performed in five phases.  In the first phase, the Layer I representation is created automatically from the algorithm.
In the second phase, Layer II is generated automatically by applying the schedule to Layer I.  Only scheduling commands that apply loop nest transformations and that tag loop level dimensions for execution on a particular hardware unit are considered to generate Layer II from Layer I.
Commands for buffer allocation and data-layout mapping are considered in the third phase.  These commands augment the Layer II representation; the result constitutes Layer III.  The newly added buffer allocation statements are not yet scheduled.  In the fourth phase, scheduling commands that map buffers to different memory hierarchies (\texttt{tag\_gpu\_global()}, \texttt{tag\_gpu\_shared()}, \texttt{tag\_gpu\_local()} and \texttt{tag\_gpu\_constant()}), those that specify communication (\texttt{host\_to\_device()}, \texttt{device\_to\_host()}, \texttt{copy\_at()}) and synchronization are applied.  All the new operations that are added in this phase and in the previous one are scheduled.  The result of this phase is the Layer IV representation.  In the final phase, an annotated abstract syntax tree (AST) is generated from Layer IV; this AST is traversed to generate the target code.


% through two means: \emph{time-space mapping} and \emph{introducing new statements}.

Generating Layers II, III and IV is done by applying \framework{} scheduling commands.
In the rest of this section we describe how scheduling commands transform Layers I, II, III and IV.   We also describe how target code is generated from Layer IV.

\vspace{-0.25cm}
\paragraph{Transforming Layer I into Layer II}
Transforming Layer I into Layer II is done using two types of scheduling commands: (1) commands for loop nest transformations (such as \texttt{tile()}, \texttt{split()}, \texttt{shift()}, \texttt{interchange()}); and (2) commands for mapping loop levels to hardware (such as \texttt{parallelize()}, \texttt{vectorize()}, \texttt{gpu()}).

These first type of scheduling commands is implemented by applying a map that transforms the iteration domain.  For example, when a tiling command is applied on the \texttt{by} computation in Figure~\ref{fig:algorithm}, it gets translated into the following map:

\centerline{\poly{$\{by(i,j,c) \rightarrow by(i0,j0,i1,j1,c): i0=floor(i/16) \wedge i1=i\%16 \wedge $}}
\centerline{\polyc{$ j0=floor(j/16) \wedge j1=j\%16 \wedge 0 \leq i<N \wedge 0 \leq j<N\}$}}

This map is then applied on the Layer I representation producing the Layer II representation (presented in the previous section). Composing many transformations is done by composing different maps, since the composition of two affine maps is an affine map.

The second type of commands adds \processor tags to the layer II dimensions to indicate whether which loop levels should be parallelized, vectorized, mapped to a GPU block, ...

\vspace{-0.25cm}
\paragraph{Transforming Layer II into Layer III}
This is done by augmenting Layer II with access relations.  By default, \framework{} uses identity access relations (i.e., access relations that store a computation \texttt{C(i,j)} into a buffer \texttt{C[i,j]}.  If the \texttt{store\_in()} commands is used, the access relation is deduced from that command instead.  Buffer allocations are also done while transforming Layer II into Layer III. The scheduling command \texttt{b.allocate\_at(C, i)} create a new statement that allocates the buffer \texttt{b} in the same loop nest of the computation \texttt{C} but at the loop level \texttt{i}.
The iteration domain domain of the allocation statement is deduced automatically from the iteration domain of \texttt{C} as follows: in Layer II, the iteration domain of \texttt{C} is already transformed into the time-\processor domain (i.e., C is already scheduled).  The iteration domain of \texttt{b} is equal to the iteration domain of \texttt{C} except that the dimensions after \texttt{i} (inner loop levels) are projected out (i.e., removed).

\vspace{-0.25cm}
\paragraph{Transforming Layer III into Layer IV}
Scheduling commands for data communication (send and receive), synchronization and for copying data between global, shared and local memory are all translated into statements.  For example, the \texttt{send()} and \texttt{receive()} commands are translated into function calls that will be translated during code generation into MPI calls.

\vspace{-0.25cm}
\subsection{Code Generation}

Generating code from the set of computations in Layer IV amounts to generating nested loops that visit each computation in the set, once and only once, while following the lexicographical ordering between the computations~\cite{Bas04,Iri88,Qui00}. \framework{} relies on an implementation of the Cloog~\cite{Bas04} code generation algorithm provided by the ISL library~\cite{verdoolaege_isl:_2010}. 
The \framework{} code generator takes Layer IV as input and generates an abstract syntax tree (AST).  The AST is then traversed to generate lower level code targeting specific hardware architectures.
%In the remaining of this section we provide details about targeting specific architectures from \framework{}.

\vspace{-0.25cm}
\subsubsection{Multicore CPU}

\framework{} generates LLVM for multicore CPUs.  When generating code that targets multicore shared memory systems, loop levels tagged with space \emph{cpu} dimensions are translated into parallel loops in the generated code, using OpenMP-style parallelism.  Loops tagged with the \emph{vec} space dimensions are vectorized.  Currently we only support vectorization of loops that do not contain control flow.

\vspace{-0.25cm}
\subsubsection{GPU (CUDA)}
For GPU code generation, data copy commands and information about where to store buffers (shared, constant, or global memory) are all provided in Layer IV.  \framework{} translates these into the equivalent data copies and buffer allocations in the generated code.  Computation dimensions tagged with GPU thread or GPU block tags are translated into the appropriate GPU thread and block IDs in the lowered code.  The \framework{} code generator can generate coalesced array accesses and can use shared and constant memories. It can also avoid thread divergence by separating full tiles (loop nests with a size that is multiple of the tile size) from partial tile (the remaining part of a loop).
The final output of the GPU code generator is an optimized CUDA code.
%For more details about GPU code generation in the polyhedral model please refer to~\cite{pencil_pact,Verdoolaege2013PPCG}
%For GPU code, CUDA source \framework{} generates CUDA source from the AST.


\subsubsection{Distributed Memory Systems}

\framework{} utilizes MPI to generate code for distributed memory systems.  During code generation, we postprocess the generated code and convert each distributed loop into a conditional based on the rank of the executing process. For example:
\vspace{-0.15cm}
\begin{lstlisting}[numbers=none]
for(q in 1..N-1) {...} // distribute on q
\end{lstlisting}
\vspace{-0.15cm}
becomes:
\vspace{-0.15cm}
\begin{lstlisting}[escapechar=@,numbers=none]
q = get_rank(); if (q@$\geq$1@ and q<N-1) {...}
\end{lstlisting}

%\vspace{-0.25cm}
%\subsection{Checking the Validity of Schedules}

%To check the validity of transformations, we first compute the dependences of the input program using array data-flow analysis~\cite{feautrier_dataflow_1991}.  The original dependences (order between producers and consumers) represent the semantics of the program.
%After computing dependences, we check the validity of transformations using violated dependence analysis~\cite{vasilache_violated_2006}: a schedule is valid if it preserves the original semantics of the program (i.e., if it preserves the order between producers and consumers).

\vspace{-0.25cm}
\subsection{Support for Non-Affine Iteration Spaces\label{nonaffine}}

\framework represents non-affine array accesses, non-affine loop bounds, and non-affine conditionals in a way similar to~\citet{Benabderrahmane}.
For example, a conditional is transformed into a predicate and is attached to the computation.  The list of accesses of the computation is the union of the accesses of the computation in the two branches of the conditional; this is an over-approximation. During code generation, a preprocessing step inserts the conditional back into the generated code.  The efficiency of these techniques was confirmed in the PENCIL compiler~\cite{pencil}. Our experiences in general, as well as the experiments in this paper, show that these approximations do not hamper performance.

